# PrevisÃ£o Temporal de Carga ElÃ©trica com Modelos Lineares, MLP, LSTM e TFT
### ComparaÃ§Ã£o de arquiteturas simples e complexas aplicadas Ã  ENTSO-E (FranÃ§a, Espanha e Portugal)
**Autor:** Victor M. Bertini  
**Orientador:** Prof. Fernando J. Von Zuben â€“ FEEC / UNICAMP  

---

## ğŸ“Œ VisÃ£o Geral

Este repositÃ³rio contÃ©m todo o cÃ³digo, prÃ©-processamento, experimentos e resultados utilizados no meu Trabalho de ConclusÃ£o de Curso (TCC), cujo objetivo foi **comparar modelos de diferentes complexidades** para previsÃ£o de carga elÃ©trica horÃ¡ria utilizando dados reais da **ENTSO-E Transparency Platform**.

A pesquisa busca responder:

> **Modelos complexos (como LSTM e Transformers) realmente superam modelos simples (Linear / MLP) em cenÃ¡rios reais e com quantidade moderada de dados?**

---

## ğŸ“Š Dados

- **Fonte:** ENTSO-E Transparency Platform  
- **MÃ©trica:** Carga ElÃ©trica Total (Total Load)  
- **PaÃ­ses:** FranÃ§a (FR), Espanha (ES), Portugal (PT)  
- **PerÃ­odo:** 2021â€“2025  
- **FrequÃªncia:** HorÃ¡ria  
- **Total por paÃ­s:** ~35.000 amostras  

Motivos da escolha:
- Dados reais e confiÃ¡veis  
- Alta resoluÃ§Ã£o temporal  
- Baixa necessidade de limpeza  
- Cobertura longa e contÃ­nua  

---

## ğŸ§ª Problemas de PrevisÃ£o (N1, N2, N3)

Os experimentos foram organizados em trÃªs nÃ­veis progressivos:

### **N1 â€” Univariado (baseline por paÃ­s)**
- Um modelo para cada paÃ­s, olhando apenas seu histÃ³rico.
- Mede o desempenho bÃ¡sico da arquitetura.

### **N2 â€” MultipaÃ­s (aprendizado compartilhado)**
- Um Ãºnico modelo aprende FR + ES + PT juntos.
- Avalia transferÃªncia de padrÃµes entre paÃ­ses.

### **N3 â€” Robustez a RuÃ­do**
- RuÃ­do gaussiano leve adicionado Ã s entradas.
- Testa estabilidade de cada modelo.

### **VariaÃ§Ãµes A/B/C â€” diferentes lags**
TrÃªs janelas de observaÃ§Ã£o para estudar o impacto do lookback.

---

## ğŸ”§ PrÃ©-Processamento

Todo o pipeline utiliza uma **classe Ãºnica** responsÃ¡vel por:

### âœ” OrganizaÃ§Ã£o e limpeza
- OrdenaÃ§Ã£o temporal
- Tratamento mÃ­nimo de valores ausentes
- ManutenÃ§Ã£o da integridade das sÃ©ries

### âœ” CodificaÃ§Ã£o temporal (sen/cos)
- Hora, dia, mÃªs â†’ representaÃ§Ãµes cÃ­clicas  
- MantÃ©m periodicidade natural da carga elÃ©trica

### âœ” NormalizaÃ§Ã£o por paÃ­s
- Z-score independente para FR, ES, PT  
- EstatÃ­sticas salvas em `.meta.json`

### âœ” Dados preparados conforme o modelo
- **Linear / MLP:** vetores flatten  
- **LSTM:** tensores 3D (sequÃªncias)  
- **TFT:** sequÃªncias + identificador do paÃ­s  

---

## ğŸ§  Modelos Implementados

### **RegressÃ£o Linear**
- Modelo baseline  
- Excelente em curtÃ­ssimo prazo  
- Degrada rapidamente em horizontes longos  

### **MLP (Multilayer Perceptron)**
- 3 camadas densas com ReLU  
- Melhor equilÃ­brio entre simplicidade e desempenho  
- EstÃ¡vel ao longo do horizonte  

### **LSTM**
- 2 camadas recorrentes empilhadas  
- Forte em dependÃªncias de longo prazo  
- Requer mais dados e custo computacional maior  

### **TFT (Temporal Fusion Transformer)**
- ImplementaÃ§Ã£o via PyTorch Forecasting  
- Inclui atenÃ§Ã£o, gating e seleÃ§Ã£o de variÃ¡veis  
- NÃ£o convergiu adequadamente com o volume atual (~35k por paÃ­s)  

---

## âš™ Treinamento e HiperparÃ¢metros

### DivisÃ£o temporal
- Treino: Jan/2021 â€“ Set/2024  
- ValidaÃ§Ã£o: Outâ€“Dez/2024  
- Teste: Janâ€“Mar/2025  

### Ajuste de hiperparÃ¢metros
- Feito com **Optuna**  
- Objetivo: **minimizar erro de validaÃ§Ã£o**  
- Resultados registrados com **MLflow**

### MÃ©tricas avaliadas
- MAE  
- MSE  
- RMSE  
- RÂ²  
- CorrelaÃ§Ã£o de Pearson  

---

## ğŸ“ˆ Resultados (Resumo)

### **Lineares**
- Melhores nas primeiras 24 horas
- DegradaÃ§Ã£o rÃ¡pida em leads longos

### **MLP**
- Inicialmente ligeiramente inferior ao linear  
- Muito mais estÃ¡vel ao longo do horizonte  
- Melhor desempenho mÃ©dio geral  

### **LSTM**
- Fraco no curtÃ­ssimo prazo  
- Melhor em previsÃµes longas  
- Adequado quando hÃ¡ dependÃªncias estendidas  

### **TFT**
- NÃ£o convergiu  
- Requer datasets muito maiores  

---

## ğŸ ConclusÃµes

1. **Modelos simples sÃ£o extremamente competitivos.**  
2. **A complexidade nÃ£o garante melhor desempenho.**  
3. **MLP apresentou o melhor equilÃ­brio entre custo e performance.**  
4. **LSTMs valem a pena apenas em horizontes longos.**  
5. **Transformers (TFT) nÃ£o sÃ£o eficazes com datasets moderados.**  

### RecomendaÃ§Ãµes prÃ¡ticas:
- **CurtÃ­ssimo prazo:** Linear  
- **Curto/mÃ©dio prazo:** MLP  
- **MÃ©dio/longo prazo:** LSTM  

---

## ğŸ“‚ Estrutura do RepositÃ³rio

â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Dados originais coletados da ENTSO-E
â”‚   â”œâ”€â”€ processed/          # Dados apÃ³s prÃ©-processamento
â”‚   â””â”€â”€ treinamento/        # TFRecords e Parquets finais usados nos modelos
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ Coleta_dados.ipynb
â”‚   â”œâ”€â”€ Modelos_tensorflow.ipynb
â”‚   â””â”€â”€ Modelos_pytorch.ipynb
â”‚
â”œâ”€â”€ preprocessor.py         # Classe Ãºnica de encoding, decoding e normalizaÃ§Ã£o
â”œâ”€â”€ models/                 # Arquiteturas lineares, MLP, LSTM e TFT
â”œâ”€â”€ results/                # GrÃ¡ficos, mÃ©tricas, validaÃ§Ãµes e relatÃ³rios
â”œâ”€â”€ utils/                  # FunÃ§Ãµes auxiliares
â””â”€â”€ README.md


---

## ğŸ”— Links Ãšteis

- **RepositÃ³rio:** https://github.com/vm-bertini/TCC-2025  
- **Resultados (grÃ¡ficos):** disponÃ­vel no Google Drive  
- **Paper do TFT:** https://arxiv.org/abs/1912.09363  

---

## ğŸ“œ LicenÃ§a
MIT License â€“ livre para uso acadÃªmico.


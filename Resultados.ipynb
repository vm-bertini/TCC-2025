{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db5d9d0",
   "metadata": {},
   "source": [
    "# Utilit√°rios Unificados ‚Äî Modelos, Datasets e Ru√≠do\n",
    "\n",
    "Este arquivo re√∫ne tr√™s fun√ß√µes principais, com interface unificada e documenta√ß√£o clara:\n",
    "\n",
    "1. `load_model_unificado(modelo, caminho, ...)`\n",
    "   - Carrega qualquer modelo: `linear`, `mlp`, `lstm` (Keras) ou `tft` (PyTorch Forecasting).\n",
    "   - Aceita arquivo/diret√≥rio EXATO ou uma pasta raiz para descoberta recursiva.\n",
    "\n",
    "2. Carregamento de dados (Parquet)\n",
    "   - `linear/mlp/lstm` ‚Üí Parquet com `*.meta.json` contendo `x_dim`, `y_dim` (e `seq_len`, `lead` no LSTM).\n",
    "   - `tft` ‚Üí Parquet (padr√£o: retorna DataFrame; opcional: cria `TimeSeriesDataSet`).\n",
    "\n",
    "3. `add_noise_features(obj, sigma, tipo, ...)`\n",
    "   - Adiciona ru√≠do GAUSSIANO somente nas FEATURES.\n",
    "   - `tipo='tfdata'` ‚Üí aplica em `tf.data.Dataset` (x,y).\n",
    "   - `tipo='tft'` ‚Üí aplica em batches de `TimeSeriesDataSet`/`DataLoader` (chaves `encoder_cont`/`decoder_cont`).\n",
    "\n",
    "> Observa√ß√£o: O notebook foi simplificado para Parquet apenas (sem TFRecords)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd8ef53",
   "metadata": {},
   "source": [
    "## 1) Carregamento Unificado de Modelos\n",
    "\n",
    "Contrato r√°pido:\n",
    "- Entradas:\n",
    "  - `modelo`: `linear` | `mlp` | `lstm` | `tft`\n",
    "  - `caminho`: arquivo/diret√≥rio exato OU uma pasta para varredura recursiva\n",
    "  - `prefer_exts` (opcional): lista de extens√µes a priorizar (ex.: `[\".cpfg\", \".ckpt\"]` para TFT)\n",
    "  - `allow_unsafe` (bool): permite desserializa√ß√£o insegura apenas para artefatos LOCAIS (Lambda em Keras)\n",
    "- Sa√≠das: `(obj_modelo, info)`\n",
    "  - `obj_modelo`: instancia do modelo carregado (Keras ou TemporalFusionTransformer)\n",
    "  - `info`: dicion√°rio com metadados √∫teis (`path`, `backend`, `kind`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4ba9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 11:58:57.934162: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762873140.061900  859850 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9190 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:06:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762873140.061900  859850 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9190 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:06:00.0, compute capability: 8.6\n",
      "/home/victor-bertini/Documentos/tcc_2025/TCC-2025/tfc_venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 6 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "/home/victor-bertini/Documentos/tcc_2025/TCC-2025/tfc_venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 6 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TensorFlow model loaded.\n",
      "‚úÖ TensorFlow model loaded.\n",
      "‚úÖ TensorFlow model loaded.\n",
      "‚úÖ TensorFlow model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_859850/1626726152.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PyTorch Lightning checkpoint loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor-bertini/Documentos/tcc_2025/TCC-2025/tfc_venv/lib/python3.12/site-packages/pytorch_forecasting/models/base/_base_model.py:28: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# Carregamento dos modelos treinados\n",
    "import torch\n",
    "from tensorflow import keras\n",
    "import json, os\n",
    "\n",
    "def load_model(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"‚ùå File not found: {path}\")\n",
    "\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "\n",
    "    # === Load model ===\n",
    "    if ext == \".keras\":\n",
    "        model = keras.models.load_model(path)\n",
    "        print(\"‚úÖ TensorFlow model loaded.\")\n",
    "    elif ext in [\".ckpt\", \".cptk\"]:\n",
    "        model = torch.load(path, map_location=\"cpu\")\n",
    "        print(\"‚úÖ PyTorch Lightning checkpoint loaded.\")\n",
    "    else:\n",
    "        raise ValueError(f\"‚ùå Unsupported file extension: {ext}\")\n",
    "\n",
    "    # === Load optional JSON config ===\n",
    "    json_path = f\"{os.path.splitext(path)[0]}.model.json\"\n",
    "    config = None\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        print(f\"üß© Loaded config: {json_path}\")\n",
    "\n",
    "    return model, config\n",
    "\n",
    "\n",
    "## Carregando modelo linear\n",
    "linear, info_linear = load_model('./modelos/treinamento/linear.keras')\n",
    "\n",
    "## Carregando modelo MLP\n",
    "mlp, info_mlp = load_model('./modelos/treinamento/mlp.keras')\n",
    "\n",
    "## Carregando modelo LSTM\n",
    "lstm, info_lstm = load_model('./modelos/treinamento/lstm.keras')\n",
    "\n",
    "## Carregando modelo TFT\n",
    "tft, info_tft = load_model('./modelos/treinamento/TFT/tft/best.ckpt')\n",
    "\n",
    "model_list = [\n",
    "    (linear, info_linear),\n",
    "    (mlp, info_mlp),\n",
    "    (lstm, info_lstm),\n",
    "    (tft, info_tft)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64b698b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) Carregando preprocessadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd49a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Todos os preprocessadores carregados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from typing import Dict, Any, List, Tuple, Optional\n",
    "\n",
    "# === LINEAR ===\n",
    "linear_path = \"./data/treinamento/preprocessor/linear_preproc.pkl\"\n",
    "with open(linear_path, \"rb\") as f:\n",
    "    linear_preproc = pickle.load(f)\n",
    "\n",
    "\n",
    "# === LSTM ===\n",
    "lstm_path = \"./data/treinamento/preprocessor/lstm_preproc.pkl\"\n",
    "with open(lstm_path, \"rb\") as f:\n",
    "    lstm_preproc = pickle.load(f)\n",
    "\n",
    "# === TFT ===\n",
    "tft_path = \"./data/treinamento/preprocessor/tft_preproc.pkl\"\n",
    "with open(tft_path, \"rb\") as f:\n",
    "    tft_preproc = pickle.load(f)\n",
    "\n",
    "# === PREPROCESSORS DICT ===\n",
    "preprocessors = {\n",
    "    \"linear\": linear_preproc,\n",
    "    \"mlp\": linear_preproc,  # MLP usa o mesmo pr√©-processador do Linear\n",
    "    \"lstm\": lstm_preproc,\n",
    "    \"tft\": tft_preproc,\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Todos os preprocessadores carregados com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0afe84",
   "metadata": {},
   "source": [
    "# Fun√ß√µes helper para an√°lise dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e44a40",
   "metadata": {},
   "source": [
    "## Fun√ß√µes de coleta de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d85f6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from preprocessor import LinearPreprocessor, LSTMPreprocessor, TFTPreprocessor\n",
    "import numpy as np\n",
    "\n",
    "def load_dataset_info(model_type: str, dataset_type: str) -> Dict[str, Any]:\n",
    "    info_path = f'./data/treinamento/{model_type}_dataset_{dataset_type}.meta.json'\n",
    "    if not os.path.exists(info_path):\n",
    "        raise FileNotFoundError(f\"‚ùå Dataset info file not found: {info_path}\")\n",
    "    with open(info_path, 'r') as f:\n",
    "        info = json.load(f)\n",
    "    return info\n",
    "\n",
    "\n",
    "\n",
    "def get_problem_df(model_type: str, lag, lead, country_list, problem_name) -> pd.DataFrame:\n",
    "    # Instanciando preprocessadores\n",
    "    dataset_info = load_dataset_info(model_type, \"test\")\n",
    "    destino_dir = f'./data/{problem_name}'\n",
    "\n",
    "    if model_type == 'linear':\n",
    "        df, dataset_info = LinearPreprocessor.load_linear_parquet_dataset(\n",
    "        data_dir=destino_dir,\n",
    "        split='test',\n",
    "        batch_size=256,\n",
    "        shuffle=True\n",
    "        )\n",
    "    elif model_type == 'lstm':\n",
    "        df,dataset_info = LSTMPreprocessor.load_lstm_parquet_dataset(\n",
    "        data_dir=destino_dir,\n",
    "        split='test',\n",
    "        batch_size=256,\n",
    "        shuffle=True\n",
    "        )\n",
    "    elif model_type == 'tft':\n",
    "        preproc = TFTPreprocessor(\n",
    "        model_name=\"TFT\",\n",
    "        seq_len=lag,\n",
    "        lead=lead,\n",
    "        country_list=country_list,\n",
    "        feature_cols=dataset_info['feature_cols'],\n",
    "        target_cols=dataset_info['target_cols'],\n",
    "        data_dir=destino_dir\n",
    "    )\n",
    "        df = preproc.load_tft_dataset('test', target_col=dataset_info['target_cols'][0])\n",
    "    else:\n",
    "        raise ValueError(f\"Modelo desconhecido: {model_type}\")\n",
    "    return df, dataset_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b52c05",
   "metadata": {},
   "source": [
    "## Fun√ß√£o de Desnormaliza√ß√£o e Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa68e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: denormalize + decode using a given Preprocessor instance\n",
    "from typing import Optional, Dict, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def denorm_decode(\n",
    "    preproc,\n",
    "    df: Optional[pd.DataFrame] = None,\n",
    "    normalization_method: Optional[str] = None,\n",
    "    *,\n",
    "    decode_time: bool = True,\n",
    "    decode_label: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Restaura um DataFrame ao estado original usando os m√©todos do *preprocessor*:\n",
    "    - denormalize(): reverte normaliza√ß√£o baseada no scaler salvo em preproc.norm_objects\n",
    "    - decode(): desfaz encodings (label e/ou time_cycle) quando metadados existirem\n",
    "\n",
    "    Par√¢metros\n",
    "    - preproc: inst√¢ncia de LinearPreprocessor | LSTMPreprocessor | TFTPreprocessor\n",
    "    - df: DataFrame a restaurar; se None, usa preproc.df_base\n",
    "    - normalization_method: qual chave usar em preproc.norm_objects; se None, usa a primeira dispon√≠vel\n",
    "    - decode_time: se True, tenta decodificar componentes c√≠clicos de tempo\n",
    "    - decode_label: se True, tenta decodificar labels categ√≥ricos (ex.: country)\n",
    "\n",
    "    Observa√ß√µes\n",
    "    - A opera√ß√£o trabalha em preproc.df_base (conforme API da classe). Sempre retorna uma c√≥pia restaurada.\n",
    "    - Para datasets LSTM salvos como (X,Y) flatten/arrays, a denormaliza√ß√£o direta n√£o se aplica aqui; use a denorm nas s√©ries base antes de gerar janelas.\n",
    "    \"\"\"\n",
    "    if df is not None:\n",
    "        preproc.df_base = df.copy()\n",
    "    elif getattr(preproc, 'df_base', None) is None or preproc.df_base.empty:\n",
    "        raise ValueError(\"df n√£o fornecido e preproc.df_base est√° vazio.\")\n",
    "\n",
    "    # 1) Denormalize, se houver scaler registrado\n",
    "    if normalization_method is None:\n",
    "        # pega a primeira chave dispon√≠vel (ex.: 'minmax' ou 'standard')\n",
    "        norm_keys = list((getattr(preproc, 'norm_objects', {}) or {}).keys())\n",
    "        normalization_method = norm_keys[0] if norm_keys else None\n",
    "\n",
    "    if normalization_method:\n",
    "        try:\n",
    "            preproc.denormalize(normalization_method=normalization_method)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Falha ao denormalizar com m√©todo '{normalization_method}': {e}\")\n",
    "    else:\n",
    "        print(\"[INFO] Nenhum m√©todo de normaliza√ß√£o encontrado no preprocessor; pulando denormalize().\")\n",
    "\n",
    "    # 2) Decodes opcionais\n",
    "    if decode_label and 'label' in getattr(preproc, 'encod_objects', {}):\n",
    "        try:\n",
    "            preproc.decode(encode_method='label')\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Falha ao decodificar labels: {e}\")\n",
    "\n",
    "    if decode_time and 'time_cycle' in getattr(preproc, 'encod_objects', {}):\n",
    "        try:\n",
    "            preproc.decode(encode_method='time_cycle', target_col='decoded_datetime')\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Falha ao decodificar time_cycle: {e}\")\n",
    "\n",
    "    return preproc.df_base.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a1ff4",
   "metadata": {},
   "source": [
    "## Fun√ß√µes de avalia√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fde0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "def sanity_check_prefetch(ds):\n",
    "    for x, y in ds.take(1):\n",
    "        print(np.std(x.numpy(), axis=0))  # per feature std\n",
    "\n",
    "\n",
    "def avaliar_modelo_keras(\n",
    "    model,\n",
    "    dataset,\n",
    "    titulo=\"Avalia√ß√£o do Modelo\",\n",
    "    problem_name=\"problema\",\n",
    "    max_samples=None,       # None ou <=0 -> usa o m√°ximo poss√≠vel\n",
    "    n_leads: int = 1,\n",
    "    save_dir=\"./resultados/graficos\",\n",
    "    show_plots: bool = True, # üëà se False, apenas salva (sem plt.show)\n",
    "    preproc=None,            # üëà IGNORADO neste fluxo simplificado\n",
    "    normalization_method: str | None = None,  # üëà IGNORADO neste fluxo simplificado\n",
    "    decode_time: bool = True,                 # üëà IGNORADO neste fluxo simplificado\n",
    "    decode_label: bool = True,                # üëà IGNORADO neste fluxo simplificado\n",
    "    model_info: dict | None = None,          # üëà IGNORADO neste fluxo simplificado\n",
    "    run_denorm_decode: bool = False,         # üëà desativado e IGNORADO\n",
    "    salvar_parquet: bool = False,            # üëà desativado e IGNORADO\n",
    "):\n",
    "    \"\"\"\n",
    "    Fluxo simplificado (sem denormalizar/decodificar e sem construir DataFrames):\n",
    "    1) Predict (e evaluate opcional) ‚Üí obt√©m Y_pred e Y_real no estado atual (as-is)\n",
    "    2) Recorta para max_samples\n",
    "    3) Calcula m√©tricas diretamente em arrays e gera gr√°ficos\n",
    "    4) N√ÉO salva datasets (Parquet/CSV) e N√ÉO realiza denormaliza√ß√£o/decodifica√ß√£o\n",
    "    \"\"\"\n",
    "    print(f\"üöÄ Avaliando modelo '{model.name}' (sem denorm/decode, sem DFs)...\")\n",
    "\n",
    "    # === Avalia√ß√£o (evaluate) - mantido para registrar m√©tricas de compile ===\n",
    "    resultados_dict = {}\n",
    "    try:\n",
    "        eval_out = model.evaluate(dataset, verbose=0, return_dict=True)\n",
    "        resultados_dict = {str(k): float(v) for k, v in eval_out.items()}\n",
    "    except TypeError:\n",
    "        try:\n",
    "            resultados = model.evaluate(dataset, verbose=0)\n",
    "            if not isinstance(resultados, (list, tuple)):\n",
    "                resultados = [resultados]\n",
    "            metric_names = getattr(model, \"metrics_names\", []) or []\n",
    "            resultados_dict = {str(k): float(v) for k, v in zip(metric_names, resultados)}\n",
    "        except Exception:\n",
    "            resultados_dict = {}\n",
    "    # === Previs√µes ===\n",
    "    preds, trues = [], []\n",
    "\n",
    "    for X_batch, Y_batch in dataset:\n",
    "        p = model.predict(X_batch, verbose=0)\n",
    "        preds.append(p)\n",
    "        trues.append(Y_batch)\n",
    "    Y_pred = np.concatenate(preds, axis=0)\n",
    "    Y_real = np.concatenate(trues, axis=0)\n",
    "\n",
    "    Y_pred = np.squeeze(Y_pred)\n",
    "    Y_real = np.squeeze(Y_real)\n",
    "\n",
    "    # Limite de amostras\n",
    "    if max_samples is None or max_samples <= 0 or max_samples > len(Y_real):\n",
    "        max_samples = len(Y_real)\n",
    "    print(f\"üìè Utilizando {max_samples} amostras para os gr√°ficos.\")\n",
    "    Y_real = Y_real[:max_samples]\n",
    "    Y_pred = Y_pred[:max_samples]\n",
    "\n",
    "    # === Diret√≥rio de sa√≠da para imagens/JSON de m√©tricas ===\n",
    "    output_dir = os.path.join(save_dir, problem_name, model.name)\n",
    "    if os.path.exists(output_dir):\n",
    "        print(f\"üßπ Limpando diret√≥rio anterior: {output_dir}\")\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    used_scale = 'as-is'\n",
    "\n",
    "    # === Arrays para m√©tricas/plots (j√° est√£o 'as-is') ===\n",
    "    Y_real_used = Y_real\n",
    "    Y_pred_used = Y_pred\n",
    "\n",
    "    # === M√©tricas gerais (overall) ===\n",
    "    diff = Y_pred_used - Y_real_used\n",
    "    abs_diff = np.abs(diff)\n",
    "    mae_all = float(np.mean(abs_diff))\n",
    "    mse_all = float(np.mean(diff ** 2))\n",
    "    rmse_all = float(np.sqrt(mse_all))\n",
    "\n",
    "    # Correla√ß√£o de Pearson (overall, vetores achatados)\n",
    "    y_true_flat = Y_real_used.reshape(-1)\n",
    "    y_pred_flat = Y_pred_used.reshape(-1)\n",
    "    if y_true_flat.size > 1 and np.std(y_true_flat) > 0 and np.std(y_pred_flat) > 0:\n",
    "        corr_all = float(np.corrcoef(y_true_flat, y_pred_flat)[0, 1])\n",
    "    else:\n",
    "        corr_all = float('nan')\n",
    "\n",
    "    ss_res = float(np.sum((y_true_flat - y_pred_flat) ** 2))\n",
    "    ss_tot = float(np.sum((y_true_flat - np.mean(y_true_flat)) ** 2))\n",
    "    r2_all = float(1.0 - ss_res / ss_tot) if ss_tot > 0 else float('nan')\n",
    "\n",
    "    resultados_dict[\"mae\"] = mae_all\n",
    "    resultados_dict[\"mse\"] = mse_all\n",
    "    resultados_dict[\"rmse\"] = rmse_all\n",
    "    resultados_dict[\"correlacao_pearson\"] = corr_all\n",
    "    resultados_dict[\"r2\"] = r2_all\n",
    "    resultados_dict[\"used_scale\"] = used_scale\n",
    "\n",
    "    # Persistir m√©tricas JSON (permanece permitido)\n",
    "    try:\n",
    "        with open(os.path.join(output_dir, \"metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(resultados_dict, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"üíæ metrics.json salvo em: {os.path.join(output_dir, 'metrics.json')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Falha ao salvar metrics.json: {e}\")\n",
    "\n",
    "    # === Tabela de m√©tricas gerais (overall_metrics.png) ===\n",
    "    numeric_items = [(k, v) for k, v in resultados_dict.items() if isinstance(v, (int, float))]\n",
    "    if numeric_items:\n",
    "        fig, ax = plt.subplots(figsize=(8, 0.4 * len(numeric_items) + 1))\n",
    "        ax.axis('off')\n",
    "        col_labels = [\"M√©trica\", \"Valor\"]\n",
    "        table_data = [[k, f\"{v:.6f}\"] for k, v in numeric_items]\n",
    "        table = ax.table(cellText=table_data, colLabels=col_labels, loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(9)\n",
    "        table.scale(1, 1.1)\n",
    "        ax.set_title(f\"{titulo} ‚Äî M√©tricas Gerais ({used_scale})\", pad=12)\n",
    "        overall_path = os.path.join(output_dir, \"overall_metrics.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(overall_path, dpi=150)\n",
    "        if show_plots:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        print(f\"üíæ Tabela de m√©tricas gerais salva em: {overall_path}\\n\")\n",
    "\n",
    "    # === M√©tricas por lead + gr√°ficos comparativos ===\n",
    "    per_lead_metrics = {}\n",
    "    if isinstance(Y_real_used, np.ndarray) and Y_real_used.ndim > 1:\n",
    "        effective_leads = min(Y_real_used.shape[1], n_leads)\n",
    "        for i in range(effective_leads):\n",
    "            y_t = Y_real_used[:, i]\n",
    "            y_p = Y_pred_used[:, i]\n",
    "            d = y_p - y_t\n",
    "            ad = np.abs(d)\n",
    "            mae_i = float(np.mean(ad))\n",
    "            mse_i = float(np.mean(d ** 2))\n",
    "            rmse_i = float(np.sqrt(mse_i))\n",
    "            # Correla√ß√£o de Pearson por lead\n",
    "            if y_t.size > 1 and np.std(y_t) > 0 and np.std(y_p) > 0:\n",
    "                corr_i = float(np.corrcoef(y_t, y_p)[0, 1])\n",
    "            else:\n",
    "                corr_i = float('nan')\n",
    "            ss_res_i = float(np.sum((y_t - y_p) ** 2))\n",
    "            ss_tot_i = float(np.sum((y_t - np.mean(y_t)) ** 2))\n",
    "            r2_i = float(1.0 - ss_res_i / ss_tot_i) if ss_tot_i > 0 else float('nan')\n",
    "            per_lead_metrics.setdefault('mae', []).append(mae_i)\n",
    "            per_lead_metrics.setdefault('mse', []).append(mse_i)\n",
    "            per_lead_metrics.setdefault('rmse', []).append(rmse_i)\n",
    "            per_lead_metrics.setdefault('correlacao_pearson', []).append(corr_i)\n",
    "            per_lead_metrics.setdefault('r2', []).append(r2_i)\n",
    "\n",
    "        # Gera gr√°fico comparativo para cada m√©trica\n",
    "        def _plot_metric_series(metric_name, values):\n",
    "            fig, ax = plt.subplots(figsize=(9, 4))\n",
    "            xs = np.arange(1, len(values) + 1)\n",
    "            ax.plot(xs, values, marker='o', linewidth=2, color='steelblue')\n",
    "            ax.set_title(f\"{titulo} ‚Äî {metric_name.upper()} por Lead ({used_scale})\")\n",
    "            ax.set_xlabel(\"Lead\")\n",
    "            ax.set_ylabel(metric_name.upper())\n",
    "            ax.grid(True, linestyle='--', alpha=0.6)\n",
    "            for x, v in zip(xs, values):\n",
    "                ax.annotate(f\"{v:.4f}\", (x, v), textcoords=\"offset points\", xytext=(0, -15), ha='center', fontsize=8, color='darkslategray')\n",
    "            plt.tight_layout()\n",
    "            fpath = os.path.join(output_dir, f\"metric_lead_comparison_{metric_name}.png\")\n",
    "            plt.savefig(fpath, dpi=150)\n",
    "            if show_plots:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()\n",
    "            print(f\"üíæ Gr√°fico comparativo por lead salvo: {fpath}\")\n",
    "\n",
    "        for mname, vals in per_lead_metrics.items():\n",
    "            _plot_metric_series(mname, vals)\n",
    "\n",
    "    # === Gr√°ficos Predito vs Real por lead (s√©ries) ===\n",
    "    if isinstance(Y_real_used, np.ndarray) and Y_real_used.ndim > 1:\n",
    "        effective_leads_series = min(Y_real_used.shape[1], n_leads)\n",
    "    else:\n",
    "        effective_leads_series = 1\n",
    "\n",
    "    for i in range(effective_leads_series):\n",
    "        y_true_i = Y_real_used[:, i] if (effective_leads_series > 1) else Y_real_used\n",
    "        y_pred_i = Y_pred_used[:, i] if (effective_leads_series > 1) else Y_pred_used\n",
    "        plt.figure(figsize=(9, 5))\n",
    "        plt.plot(y_true_i, label=f\"Real lead {i+1}\", color=\"black\", linewidth=2, alpha=0.8)\n",
    "        plt.plot(y_pred_i, label=f\"Previsto lead {i+1}\", color=\"tomato\", linewidth=2, alpha=0.8)\n",
    "        plt.title(f\"{titulo} - Lead {i+1} ({used_scale})\")\n",
    "        plt.xlabel(\"Amostra\")\n",
    "        plt.ylabel(\"Valor\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "        plt.tight_layout()\n",
    "        file_name = f\"predito_vs_real_lead{i+1}.png\"\n",
    "        file_path = os.path.join(output_dir, file_name)\n",
    "        plt.savefig(file_path, dpi=150)\n",
    "        if show_plots:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        print(f\"üíæ Gr√°fico Lead {i+1} salvo em: {file_path}\")\n",
    "\n",
    "    print(\"‚úÖ Avalia√ß√£o conclu√≠da.\")\n",
    "\n",
    "    result_payload = dict(resultados_dict)\n",
    "    result_payload['y_true'] = Y_real_used\n",
    "    result_payload['y_pred'] = Y_pred_used\n",
    "    if 'per_lead_metrics' in locals() and per_lead_metrics:\n",
    "        result_payload['per_lead_metrics'] = per_lead_metrics\n",
    "    return result_payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e135642",
   "metadata": {},
   "source": [
    "# N1A ‚Äî S√©rie Univariada (seq_len=72, lead=72)\n",
    "\n",
    "\n",
    "Objetivo\n",
    "- Prever 24 horas de carga √† frente com janelas de 48 horas de hist√≥rico para um √∫nico pa√≠s.\n",
    "\n",
    "\n",
    "Artefatos esperados\n",
    "- Parquet (Linear/MLP): `data/N1A/linear_dataset_{split}.parquet` + `linear_dataset_{split}.meta.json` ‚Üí { x_dim, y_dim }\n",
    "- Parquet (LSTM): `data/N1A/lstm_dataset_{split}.parquet` + `lstm_dataset_{split}.meta.json` ‚Üí { seq_len=240, lead=72, x_dim, y_dim }\n",
    "\n",
    "\n",
    "Modelos a comparar\n",
    "- Linear, MLP, LSTM (Keras) e, opcionalmente, TFT.\n",
    "\n",
    "\n",
    "M√©tricas e checks\n",
    "- MAE, RMSE, MAPE.\n",
    "- Checar: shapes conforme meta.json; aus√™ncia de NaNs; n√∫mero de amostras > 0.\n",
    "\n",
    "\n",
    "Visualiza√ß√µes sugeridas\n",
    "- Boxplot de erro por horizonte; barras de MAE por modelo; curva MAE vs horizonte.\n",
    "\n",
    "\n",
    "Notas\n",
    "- As variantes A/B s√£o obtidas reduzindo a janela/horizonte efetivos na avalia√ß√£o a partir do dataset base (240/72).\n",
    "- Padding (se houver) deve usar sentinela fixo para permitir mascaramento e ru√≠do seletivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73153dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ TimeSeriesDataSet (test) criado com 3492 amostras.\n",
      "üöÄ Avaliando modelo 'functional' (sem denorm/decode, sem DFs)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Concatenate.call().\n\n\u001b[1mDimension 1 in both shapes must be equal, but are 72 and 240. Shapes are [?,72] and [?,240]. for '{{node functional_1/concat_feats_1/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](data, functional_1/emb_repeat_1/Repeat/Reshape_1, functional_1/concat_feats_1/concat/axis)' with input shapes: [?,72,12], [?,240,16], [] and with computed input tensors: input[2] = <-1>.\u001b[0m\n\nArguments received by Concatenate.call():\n  ‚Ä¢ inputs=['tf.Tensor(shape=(None, 72, 12), dtype=float32)', 'tf.Tensor(shape=(None, 240, 16), dtype=float32)']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     22\u001b[39m ds_tft, tft_info = get_problem_df(\n\u001b[32m     23\u001b[39m     model_type=\u001b[33m'\u001b[39m\u001b[33mtft\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     24\u001b[39m     lag=\u001b[32m72\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     problem_name=\u001b[33m'\u001b[39m\u001b[33mN1A\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     28\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m## Avaliando dados\u001b[39;00m\n\u001b[32m     31\u001b[39m \n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m### Avaliando modelo Linear\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m \n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m### Avaliando modelo LSTM\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[43mavaliar_modelo_keras\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_lstm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtitulo\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mModelo lstm - Problema N1A\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproblem_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mN1A\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_leads\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m72\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_plots\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreproc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreprocessors\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlstm\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlinear_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_denorm_decode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43msalvar_parquet\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m               \u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# ### Avaliando modelo TFT\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# avaliar_modelo_keras(\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m#     model=tft,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m \u001b[38;5;66;03m#     salvar_parquet=True               \u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mavaliar_modelo_keras\u001b[39m\u001b[34m(model, dataset, titulo, problem_name, max_samples, n_leads, save_dir, show_plots, preproc, normalization_method, decode_time, decode_label, model_info, run_denorm_decode, salvar_parquet)\u001b[39m\n\u001b[32m     42\u001b[39m resultados_dict = {}\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     eval_out = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     resultados_dict = {\u001b[38;5;28mstr\u001b[39m(k): \u001b[38;5;28mfloat\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m eval_out.items()}\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/tcc_2025/TCC-2025/tfc_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/tcc_2025/TCC-2025/tfc_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[31mValueError\u001b[39m: Exception encountered when calling Concatenate.call().\n\n\u001b[1mDimension 1 in both shapes must be equal, but are 72 and 240. Shapes are [?,72] and [?,240]. for '{{node functional_1/concat_feats_1/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](data, functional_1/emb_repeat_1/Repeat/Reshape_1, functional_1/concat_feats_1/concat/axis)' with input shapes: [?,72,12], [?,240,16], [] and with computed input tensors: input[2] = <-1>.\u001b[0m\n\nArguments received by Concatenate.call():\n  ‚Ä¢ inputs=['tf.Tensor(shape=(None, 72, 12), dtype=float32)', 'tf.Tensor(shape=(None, 240, 16), dtype=float32)']"
     ]
    }
   ],
   "source": [
    "# Carregamento dos dataset N1A (Parquet)\n",
    "\n",
    "# linear/mlp (iguais)\n",
    "ds_linear, linear_info = get_problem_df(\n",
    "    model_type='linear',\n",
    "    lag=72,\n",
    "    lead=72,\n",
    "    country_list=['ES'],\n",
    "    problem_name='N1A'\n",
    ")\n",
    "\n",
    "# lstm\n",
    "ds_lstm, lstm_info = get_problem_df(\n",
    "    model_type='lstm',\n",
    "    lag=72,\n",
    "    lead=72,\n",
    "    country_list=['ES'],\n",
    "    problem_name='N1A'\n",
    ")\n",
    "\n",
    "tft\n",
    "ds_tft, tft_info = get_problem_df(\n",
    "    model_type='tft',\n",
    "    lag=72,\n",
    "    lead=72,\n",
    "    country_list=['ES'],\n",
    "    problem_name='N1A'\n",
    ")\n",
    "\n",
    "## Avaliando dados\n",
    "\n",
    "### Avaliando modelo Linear\n",
    "# avaliar_modelo_keras(\n",
    "#     model=linear,\n",
    "#     dataset=ds_linear,\n",
    "#     titulo=\"Modelo Linear - Problema N1A\",\n",
    "#     problem_name=\"N1A\",\n",
    "#     n_leads=72,\n",
    "#     max_samples=1000,\n",
    "#     show_plots=False,\n",
    "#     preproc=preprocessors['linear'],\n",
    "#     model_info=linear_info,           \n",
    "#     run_denorm_decode=True,           \n",
    "#     salvar_parquet=True               \n",
    "# )\n",
    "\n",
    "# ### Avaliando modelo MLP\n",
    "# avaliar_modelo_keras(\n",
    "#     model=mlp,\n",
    "#     dataset=ds_linear,\n",
    "#     titulo=\"Modelo MLP - Problema N1A\",\n",
    "#     problem_name=\"N1A\",\n",
    "#     n_leads=72,\n",
    "#     max_samples=1000,\n",
    "#     show_plots=False,\n",
    "#     preproc=preprocessors['mlp'],\n",
    "#     model_info=linear_info,           \n",
    "#     run_denorm_decode=True,           \n",
    "#     salvar_parquet=True               \n",
    "# )\n",
    "\n",
    "### Avaliando modelo LSTM\n",
    "avaliar_modelo_keras(\n",
    "    model=lstm,\n",
    "    dataset=ds_lstm,\n",
    "    titulo=\"Modelo lstm - Problema N1A\",\n",
    "    problem_name=\"N1A\",\n",
    "    n_leads=72,\n",
    "    max_samples=1000,\n",
    "    show_plots=False,\n",
    "    preproc=preprocessors['lstm'],\n",
    "    model_info=linear_info,           \n",
    "    run_denorm_decode=True,           \n",
    "    salvar_parquet=True               \n",
    ")\n",
    "\n",
    "# ### Avaliando modelo TFT\n",
    "# avaliar_modelo_keras(\n",
    "#     model=tft,\n",
    "#     dataset=ds_tft,\n",
    "#     titulo=\"Modelo TFT - Problema N1A\",\n",
    "#     problem_name=\"N1A\",\n",
    "#     n_leads=72,\n",
    "#     max_samples=1000,\n",
    "#     show_plots=False,\n",
    "#     preproc=preprocessors['tft'],\n",
    "#     model_info=linear_info,           \n",
    "#     run_denorm_decode=True,           \n",
    "#     salvar_parquet=True               \n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb06705",
   "metadata": {},
   "source": [
    "# N1B ‚Äî S√©rie Univariada (seq_len=168, lead=48)\n",
    "\n",
    "\n",
    "Objetivo\n",
    "- Prever 48 horas de carga √† frente com janelas de 168 horas de hist√≥rico para um √∫nico pa√≠s.\n",
    "\n",
    "\n",
    "Artefatos esperados\n",
    "- Parquet (Linear/MLP): `data/N1B/linear_dataset_{split}.parquet` + meta { x_dim, y_dim }\n",
    "- Parquet (LSTM): `data/N1B/lstm_dataset_{split}.parquet` + meta { seq_len=240, lead=72, x_dim, y_dim }\n",
    "- TFT (opcional): `data/treinamento/tft_dataset_{split}.parquet`\n",
    "\n",
    "\n",
    "Modelos a comparar\n",
    "- Linear, MLP, LSTM, TFT (opcional).\n",
    "\n",
    "\n",
    "M√©tricas e checks\n",
    "- MAE, RMSE, MAPE; valida√ß√£o de shapes e aus√™ncia de NaNs.\n",
    "\n",
    "\n",
    "Visualiza√ß√µes sugeridas\n",
    "- Barras de MAE m√©dio por modelo; curva de erro por horizonte.\n",
    "\n",
    "\n",
    "Notas\n",
    "- As variantes A/B s√£o derivadas do dataset base (240/72) reduzindo janela/horizonte na avalia√ß√£o, sem retreinar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ca18c5",
   "metadata": {},
   "source": [
    "# N1C ‚Äî S√©rie Univariada (seq_len=240, lead=72)\n",
    "\n",
    "\n",
    "Objetivo\n",
    "- Pr√©-treino/treino com a janela de 240 horas e avaliar horizonte de 72 horas.\n",
    "\n",
    "\n",
    "Artefatos esperados\n",
    "- Parquet (Linear/MLP): `data/N1C/linear_dataset_{split}.parquet` + meta { x_dim, y_dim }\n",
    "- Parquet (LSTM): `data/N1C/lstm_dataset_{split}.parquet` + meta { seq_len=240, lead=72, x_dim, y_dim }\n",
    "- TFT (opcional): `data/treinamento/tft_dataset_{split}.parquet`\n",
    "\n",
    "\n",
    "Modelos a comparar\n",
    "- Linear, MLP, LSTM, TFT (opcional).\n",
    "\n",
    "\n",
    "M√©tricas e checks\n",
    "- MAE, RMSE, MAPE; n√∫mero de amostras por split; coer√™ncia entre seq_len/lead do meta e shapes efetivos.\n",
    "\n",
    "\n",
    "Visualiza√ß√µes sugeridas\n",
    "- Curva comparativa de MAE vs horizonte; top‚Äëk modelos por MAE.\n",
    "\n",
    "\n",
    "Notas\n",
    "- Esta variante (C) √© a base m√°xima de lookback e horizonte; A/B s√£o obtidas por redu√ß√£o na avalia√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264ad282",
   "metadata": {},
   "source": [
    "# N2A ‚Äî M√∫ltiplos Pa√≠ses (seq_len=72, lead=24)\n",
    "\n",
    "\n",
    "Objetivo\n",
    "- Prever 24 horas com 72 horas de hist√≥rico, agrupando por pa√≠s.\n",
    "\n",
    "\n",
    "Artefatos esperados\n",
    "- Parquet (Linear/MLP): `data/N2A/linear_dataset_{split}.parquet` + meta\n",
    "- Parquet (LSTM): `data/N2A/lstm_dataset_{split}.parquet` + meta { seq_len=240, lead=72, x_dim, y_dim }\n",
    "- TFT (recomendado): `data/treinamento/tft_dataset_{split}.parquet` (colunas: _group_id=country, time_idx crescente por grupo, quantity_MW)\n",
    "\n",
    "\n",
    "Modelos a comparar\n",
    "- Linear, MLP, LSTM (podem exigir codifica√ß√£o/flatten por grupo);\n",
    "- TFT (nativamente multi‚Äëgrupo).\n",
    "\n",
    "\n",
    "M√©tricas e checks\n",
    "- MAE/RMSE por pa√≠s e globais; n√∫mero de grupos; equil√≠brio de amostras por grupo.\n",
    "\n",
    "\n",
    "Visualiza√ß√µes sugeridas\n",
    "- Barras de MAE por modelo; facetas por pa√≠s; curva MAE vs horizonte.\n",
    "\n",
    "\n",
    "Notas\n",
    "- As variantes A/B/C partem do dataset base (240/72), aplicando janelas/horizontes reduzidos na avalia√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b4db9d",
   "metadata": {},
   "source": [
    "# N2B ‚Äî M√∫ltiplos Pa√≠ses (seq_len=168, lead=48)\n",
    "\n",
    "\n",
    "Objetivo\n",
    "- Prever 48 horas com 168 horas de hist√≥rico, agrupado por pa√≠s.\n",
    "\n",
    "\n",
    "Artefatos esperados\n",
    "- Parquet (Linear/MLP): `data/N2B/linear_dataset_{split}.parquet` + meta\n",
    "- Parquet (LSTM): `data/N2B/lstm_dataset_{split}.parquet` + meta { seq_len=240, lead=72, x_dim, y_dim }\n",
    "- TFT (recomendado): `data/treinamento/tft_dataset_{split}.parquet` com `_group_id`, `time_idx`, target.\n",
    "\n",
    "\n",
    "Modelos a comparar\n",
    "- Linear, MLP, LSTM; TFT.\n",
    "\n",
    "\n",
    "M√©tricas e checks\n",
    "- MAE/RMSE por pa√≠s e agregadas; distribui√ß√£o de amostras por grupo.\n",
    "\n",
    "\n",
    "Visualiza√ß√µes sugeridas\n",
    "- Barras de MAE por modelo; linhas por horizonte; painel por pa√≠s.\n",
    "\n",
    "\n",
    "Notas\n",
    "- Variantes A/B/C usam janelas/horizontes efetivos na avalia√ß√£o; base: 240/72."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1278bb",
   "metadata": {},
   "source": [
    "# N2C ‚Äî M√∫ltiplos Pa√≠ses (seq_len=240, lead=72)\n",
    "\n",
    "\n",
    "Objetivo\n",
    "- Prever 72 horas com 240 horas de hist√≥rico, agrupado por pa√≠s. Esta variante √© a base para reuso em A/B.\n",
    "\n",
    "\n",
    "Artefatos esperados\n",
    "- Parquet (Linear/MLP): `data/N2C/linear_dataset_{split}.parquet` + meta\n",
    "- Parquet (LSTM): `data/N2C/lstm_dataset_{split}.parquet` + meta { seq_len=240, lead=72, x_dim, y_dim }\n",
    "- TFT (recomendado): `data/treinamento/tft_dataset_{split}.parquet` (agrupado por `_group_id`).\n",
    "\n",
    "\n",
    "Modelos a comparar\n",
    "- Linear, MLP, LSTM, TFT.\n",
    "\n",
    "\n",
    "M√©tricas e checks\n",
    "- MAE, RMSE, MAPE; compara√ß√£o por pa√≠s; checagem de time_idx e integridade por grupo.\n",
    "\n",
    "\n",
    "Visualiza√ß√µes sugeridas\n",
    "- Curva MAE vs horizonte; ranking de modelos por pa√≠s e global.\n",
    "\n",
    "\n",
    "Notas\n",
    "- Base usa seq_len=240 e lead=72; varia√ß√µes A/B podem ser avaliadas reduzindo janela no dataset sem retreino."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dffd95",
   "metadata": {},
   "source": [
    "# N3 ‚Äî Robustez a Ru√≠do (sobre N2)\n",
    "\n",
    "Objetivo\n",
    "- Medir degrada√ß√£o de desempenho sob ru√≠do gaussiano nas FEATURES (teste), mantendo r√≥tulos intactos.\n",
    "\n",
    "Configura√ß√£o\n",
    "- Conjuntos: use os datasets do N2 (A/B/C).\n",
    "- Intensidades: œÉ ‚àà {0.00, 0.01, 0.03, 0.05, 0.10}.\n",
    "- Aplica√ß√£o:\n",
    "  - Keras/tf.data: `add_noise_features(ds, sigma, tipo='tfdata', pad_sentinel=-999.0)`.\n",
    "  - TFT: `add_noise_features(tft_ds ou dataloader, sigma, tipo='tft', batch_size=..., train=False)`.\n",
    "\n",
    "M√©tricas e checks\n",
    "- MAE/RMSE por sigma; checar preserva√ß√£o de sentinela (TF) e invari√¢ncia de Y.\n",
    "\n",
    "Visualiza√ß√µes sugeridas\n",
    "- Curvas MAE vs œÉ por modelo; heatmap de degrada√ß√£o por horizonte e sigma.\n",
    "\n",
    "Notas\n",
    "- Aplique ru√≠do ap√≥s normaliza√ß√£o das features.\n",
    "- N√£o altere o treino; apenas avalia√ß√£o/benchmark.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
